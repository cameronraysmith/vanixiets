name: Test Cluster
on:
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: "Run the workflow with tmate.io debugging enabled"
        required: false
        type: boolean
        default: false
      force_run:
        description: "Force execution even if already successful"
        required: false
        type: boolean
        default: false
  workflow_call:
    inputs:
      debug_enabled:
        description: "Enable tmate debugging"
        required: false
        type: string
        default: "false"
      force_run:
        description: "Force execution even if already successful"
        required: false
        type: string
        default: "false"

concurrency:
  group: test-cluster-${{ github.event.pull_request.number || github.ref }}-${{ github.workflow }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

permissions:
  contents: read

env:
  CACHIX_BINARY_CACHE: cameronraysmith

jobs:
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6

      - name: Check execution cache
        id: cache
        uses: ./.github/actions/cached-ci-job
        with:
          check-name: test-cluster
          hash-sources: 'kubernetes/**/* justfile flake.nix flake.lock secrets/** scripts/k3d-test-coverage.sh .github/workflows/test-cluster.yaml .github/actions/setup-nix/action.yml'
          force-run: ${{ inputs.force_run }}

      - name: Prune Docker to free root space
        if: steps.cache.outputs.should-run == 'true'
        run: |
          echo "Pruning pre-cached Docker images to free root filesystem space..."
          docker system prune -af --volumes
          echo "Root filesystem after prune:"
          df -h /

      # nothing-but-nix configuration for k3d integration tests
      #
      # GitHub runners come in three disk topologies:
      #   - Single-disk (145G): /mnt is a directory ON root
      #   - Two-disk (72G+74G): /mnt is separate /dev/sdb1
      #   - Small /mnt (~20G): limited /mnt partition
      #
      # k3d tests need both:
      #   - /nix store: ~1GB for Nix derivations
      #   - Docker overlay on root: ~4GB for k3s, cilium, argocd images
      #
      # Using holster (never expands from root) + mnt-safe-haven:
      #   - Single-disk: mnt-safe-haven reserves ROOT space for Docker
      #   - Two-disk: mnt-safe-haven reserves /mnt space, root untouched
      #   - Small /mnt: must fit within 20GB (requires mnt-safe-haven + 1GB < 20GB)
      #
      # mnt-safe-haven=15GB balances all topologies:
      #   - Requires 16GB /mnt (fits 20GB minimum)
      #   - Reserves 15GB for Docker (~4x measured 4GB usage)
      #   - Leaves 5-78GB for /nix depending on runner (need ~1GB)
      - name: Setup Nix
        if: steps.cache.outputs.should-run == 'true'
        uses: ./.github/actions/setup-nix
        with:
          installer: full
          hatchet: holster
          mnt-safe-haven: '15360'
          system: x86_64-linux

      - name: Verify Docker available
        if: steps.cache.outputs.should-run == 'true'
        run: |
          docker version
          docker info

      - name: Run k3d integration tests
        if: steps.cache.outputs.should-run == 'true'
        run: nix develop .#kubernetes --accept-flake-config -c just k3d-integration-ci

      - name: Create job result marker
        if: success() && steps.cache.outputs.should-run == 'true'
        run: |
          mkdir -p "${{ steps.cache.outputs.cache-path }}"
          cat > "${{ steps.cache.outputs.cache-path }}/marker" <<EOF
          {
            "success": true,
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "commit": "${{ github.sha }}",
            "cache_key": "${{ steps.cache.outputs.cache-key }}",
            "workflow_run_id": "${{ github.run_id }}"
          }
          EOF

      - name: Save job result to cache
        if: success() && steps.cache.outputs.should-run == 'true' && steps.cache.outputs.cache-source == 'none'
        uses: actions/cache/save@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ${{ steps.cache.outputs.cache-path }}
          key: ${{ steps.cache.outputs.cache-key }}

      - name: Collect failure diagnostics
        if: failure()
        run: |
          nix develop .#kubernetes --accept-flake-config -c bash -c '
            echo "=== k3d cluster status ==="
            k3d cluster list || true

            echo ""
            echo "=== Docker containers ==="
            docker ps -a || true

            echo ""
            echo "=== sops-age-key secret (structure only) ==="
            kubectl get secret sops-age-key -n sops-secrets-operator -o jsonpath="{.data}" 2>/dev/null | jq -r "keys" || echo "sops-age-key secret not found"

            echo ""
            echo "=== SopsSecret CRs ==="
            kubectl get sopssecrets -A 2>/dev/null || echo "No SopsSecrets found"

            echo ""
            echo "=== step-ca secrets ==="
            kubectl get secrets -n step-ca 2>/dev/null || echo "step-ca namespace not found"

            echo ""
            echo "=== sops-secrets-operator logs ==="
            kubectl logs -n sops-secrets-operator -l app.kubernetes.io/name=sops-secrets-operator --tail=50 2>/dev/null || echo "sops-secrets-operator logs not available"

            echo ""
            echo "=== sops-secrets-operator pod status ==="
            kubectl get pods -n sops-secrets-operator -o wide 2>/dev/null || echo "sops-secrets-operator namespace not found"

            echo ""
            echo "=== k3d server logs (last 50 lines) ==="
            docker logs k3d-dev-server-0 --tail 50 2>&1 || true

            echo ""
            echo "=== ArgoCD Applications ==="
            kubectl get applications -n argocd -o yaml 2>/dev/null || echo "ArgoCD not deployed"

            echo ""
            echo "=== Non-running pods ==="
            kubectl get pods -A --field-selector=status.phase!=Running 2>/dev/null || echo "kubectl not available"

            echo ""
            echo "=== Pod events (warnings/errors) ==="
            kubectl get events -A --field-selector=type!=Normal --sort-by=.lastTimestamp 2>/dev/null | tail -50 || true
          '

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: chainsaw-reports
          path: |
            /tmp/chainsaw-*/
          if-no-files-found: ignore
          retention-days: 7
