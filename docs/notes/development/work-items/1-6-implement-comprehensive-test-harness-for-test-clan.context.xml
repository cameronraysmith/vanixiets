<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>6</storyId>
    <title>Implement Comprehensive Test Harness for test-clan Infrastructure Validation</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-11-05</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/notes/development/work-items/1-6-implement-comprehensive-test-harness-for-test-clan.md</sourceStoryPath>
    <revisionContext>Revised after phase-0-tests failure analysis and comprehensive technical research</revisionContext>
  </metadata>

  <story>
    <asA>Infrastructure developer working on test-clan refactoring</asA>
    <iWant>A comprehensive test suite that validates existing functionality and defines expected dendritic capabilities</iWant>
    <soThat>I can confidently refactor test-clan to dendritic flake-parts compliance with zero regression in critical infrastructure functionality</soThat>
    <tasks>
### Task 1: Setup Test Infrastructure with Correct Patterns (2-3 hours)
1. Add nix-unit to flake.nix inputs and import flake module
   - inputs.nix-unit.url = "github:nix-community/nix-unit";
   - Add to imports: inputs.nix-unit.modules.flake.default
2. Modify flake.nix to use top@ pattern for accessing complete flake outputs
   - Change signature: top@{ withSystem, config, lib, ... }:
   - This enables access to top.config.flake from flake level
3. Create test directory structure
   - tests/nix-unit/ for simple property tests (nix-unit expr/expected)
   - tests/integration/ for complex derivation tests (withSystem)
4. Verify no circular dependencies
   - Run nix flake show to confirm no infinite recursion
   - This validates the flake structure before writing tests

### Task 2: Implement Simple Property Tests via nix-unit (2-3 hours)
Pattern: Define test DATA as strings in perSystem, executed by nix-unit binary

1. Create tests/nix-unit/regression.nix
   - RT-1: Terraform output structure validation using expr/expected
2. Create tests/nix-unit/invariant.nix
   - IT-1: Clan inventory structure
   - IT-2: Clan service targeting
   - IT-3: specialArgs propagation
3. Create tests/nix-unit/feature.nix
   - FT-1: import-tree discovery (expected to fail)
   - FT-2: Namespace exports (expected to fail)
4. Import test suites in perSystem using nix-unit.tests option

### Task 3: Implement Complex Tests via withSystem (2-3 hours)
Pattern: Define tests at flake level using withSystem for perSystem context + flake outputs

1. Create tests/integration/machine-builds.nix
   - RT-2: NixOS closure validation
   - RT-3: Machine configurations build
   - Access flake.nixosConfigurations via top.config.flake parameter
2. Create tests/integration/vm-boot.nix
   - VT-1: VM boot tests for all machines using pkgs.testers.runNixOSTest
3. Integrate complex tests at flake level
   - Use lib.genAttrs config.systems with withSystem
   - Pass top.config.flake to test modules for flake output access
   - Access pkgs from perSystem context via withSystem

### Task 4: Validation and Verification (1 hour)
1. Verify no circular dependencies
   - Run nix flake show (should complete without errors)
   - Confirm all checks are listed in output
2. Test individual checks
   - nix build .#checks.x86_64-linux.nix-unit (simple property tests)
   - nix build .#checks.x86_64-linux.machine-builds
   - nix build .#checks.x86_64-linux.vm-boot
3. Run complete test suite
   - nix flake check (may take several minutes for VM tests)
4. Verify test behavior
   - Regression tests: PASS
   - Invariant tests: PASS
   - Feature tests: FAIL (expected - dendritic features not implemented)
   - Integration tests: PASS
5. Test failure detection
   - Temporarily break a test condition
   - Verify check fails appropriately
   - Restore condition and verify check passes again

### Task 5: Documentation (30 minutes)
1. Document test execution in story completion notes
2. Note any deviations from planned approach
3. Record test execution times
4. List any tests that were skipped or deferred
    </tasks>
  </story>

  <acceptanceCriteria>
### AC1: Test Infrastructure Setup
- [ ] nix-unit added to flake inputs with flake module imported
- [ ] Test directory structure created: tests/nix-unit/ and tests/integration/
- [ ] flake.nix uses top@ pattern for accessing complete flake outputs
- [ ] Simple tests defined in perSystem.nix-unit.tests (nix-unit pattern)
- [ ] Complex tests defined in flake.checks using withSystem (withSystem pattern)
- [ ] nix flake show displays checks without infinite recursion errors

### AC2: Regression Tests Implemented and Passing
- [ ] RT-1: Terraform output equivalence test implemented using nix-unit expr/expected
- [ ] RT-2: NixOS configuration closure test implemented using withSystem
- [ ] RT-3: Machine configurations build test implemented using withSystem
- [ ] All regression tests avoid circular dependencies (no access to config.flake or inputs.self from perSystem)
- [ ] All regression tests pass with baseline snapshots captured

### AC3: Invariant Tests Implemented and Passing
- [ ] IT-1: Clan inventory structure test implemented using nix-unit expr/expected
- [ ] IT-2: Clan service targeting test implemented using nix-unit expr/expected
- [ ] IT-3: specialArgs propagation test implemented using nix-unit expr/expected
- [ ] All invariant tests defined in tests/nix-unit/invariant.nix
- [ ] All invariant tests pass (validates clan-core integration)

### AC4: Feature Tests Implemented (Expected to Fail)
- [ ] FT-1: import-tree discovery test implemented using nix-unit expr/expected
- [ ] FT-2: Namespace exports test implemented using nix-unit expr/expected
- [ ] All feature tests defined in tests/nix-unit/feature.nix
- [ ] Feature tests fail as expected (confirms test correctness - dendritic features don't exist yet)

### AC5: Integration Tests Implemented and Passing
- [ ] VT-1: VM boot tests implemented for all 3 machines using withSystem + runNixOSTest
- [ ] VM tests defined in tests/integration/vm-boot.nix at flake level
- [ ] All VMs boot successfully with base module features validated
- [ ] SSH access confirmed on all test VMs

### AC6: Validation and Integration
- [ ] nix flake check executes without errors
- [ ] All individual checks can be built: nix build .#checks.x86_64-linux.<check-name>
- [ ] nix-unit check passes: nix build .#checks.x86_64-linux.nix-unit
- [ ] Tests fail appropriately when conditions are not met (verified by temporarily breaking a test)
- [ ] No circular dependency errors during evaluation
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <artifact>
        <path>docs/notes/development/research/flake-parts-nix-unit-test-integration.md</path>
        <title>Testing Nix Flake-Parts Based Repositories: Deep Technical Research</title>
        <section>Complete Document - CRITICAL TECHNICAL REFERENCE</section>
        <snippet>AUTHORITATIVE technical research document analyzing why phase-0-tests branch failed and documenting THREE correct implementation patterns for testing flake-parts repositories. Root cause: perSystem evaluation happens BEFORE flake outputs exist, creating circular dependencies when tests try to access config.flake or inputs.self from within perSystem. Solution: Hybrid approach using (1) nix-unit expr/expected for simple tests in perSystem, (2) withSystem at flake level for complex tests needing both perSystem context and flake outputs. Includes working code examples, pitfalls to avoid, and complete validation criteria. This document is the technical specification for Story 1.6 implementation.</snippet>
      </artifact>
      <artifact>
        <path>docs/notes/development/dendritic-refactor-test-strategy.md</path>
        <title>Test Strategy: Dendritic Flake-Parts Refactoring for test-clan</title>
        <section>Complete Document (Lines 1-1913)</section>
        <snippet>Comprehensive testing strategy document providing complete test implementations for all four test categories: regression tests (terraform equivalence, NixOS closure equivalence, machine builds), invariant tests (clan inventory, service targeting, specialArgs propagation), feature tests (import-tree discovery, namespace exports, self-composition), and integration tests (VM boot validation). Includes detailed rationale for each test, expected pass/fail states, and incremental refactoring execution strategy with rollback procedures.</snippet>
      </artifact>
      <artifact>
        <path>docs/notes/development/dendritic-flake-parts-assessment.md</path>
        <title>Dendritic Architecture Assessment: test-clan</title>
        <section>Complete Document (Assessment and Trade-offs Analysis)</section>
        <snippet>Assessment concludes test-clan architecture is pragmatically sound for current scale (2-4 machines). Key findings: manual imports acceptable, specialArgs pattern dendritic-compatible (validated by drupol-dendritic-infra), current architecture suitable through Epic 1. Documents three critical architectural dimensions: module discovery scalability, module namespacing/reusability, and specialArgs compatibility with dendritic patterns.</snippet>
      </artifact>
      <artifact>
        <path>docs/notes/development/work-items/1-5-deploy-and-validate-test-clan-phase-0-infrastructure.md</path>
        <title>Story 1.5: Deploy and Validate test-clan Phase 0 Infrastructure</title>
        <section>Context for Operational VMs</section>
        <snippet>Story 1.5 delivered 2 operational Hetzner VMs (162.55.175.87, 49.13.140.183) that serve as test targets for integration tests. These VMs validate clan-core integration, zerotier networking, and base module functionality. Test harness will use these as baseline for ensuring refactoring preserves operational behavior.</snippet>
      </artifact>
    </docs>
    <code>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/flake.nix</path>
        <kind>flake configuration</kind>
        <symbol>flake inputs and outputs</symbol>
        <lines>1-52</lines>
        <reason>Current flake structure uses manual imports (lines 37-41) that will be validated by feature tests. Contains inputs including import-tree (line 14) already available. Test infrastructure will add checks to perSystem.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/flake-parts/clan.nix</path>
        <kind>clan configuration module</kind>
        <symbol>clan configuration</symbol>
        <lines>1-178</lines>
        <reason>Critical for invariant tests. Contains clan.inventory.machines (21-39), clan.inventory.instances (42-103) with service targeting, specialArgs pattern (line 19), manual machine imports (108-120), and terranix namespace exports (7-9). All invariant tests validate this structure remains unchanged.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/hosts/hetzner-ccx23/default.nix</path>
        <kind>host configuration</kind>
        <symbol>hetzner-ccx23 configuration</symbol>
        <lines>1-47</lines>
        <reason>Representative host module showing current patterns tested by regression/feature tests: relative imports to base modules (lines 4-6), srvos imports via inputs (lines 7-8), host-specific configuration. Feature tests will check for transition to namespace imports.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/base/nix-settings.nix</path>
        <kind>base module</kind>
        <symbol>nix configuration</symbol>
        <lines>1-19</lines>
        <reason>Base module that should be reused across all hosts. Currently imported via relative paths. Integration tests will validate nix experimental features (flakes) are enabled. Feature tests check for namespace export.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/base/admins.nix</path>
        <kind>base module</kind>
        <symbol>user administration</symbol>
        <lines>1-28</lines>
        <reason>Base module defining user crs58 with wheel group and sudo. Integration tests will validate user exists, wheel group membership, sudo works, zsh available. Regression tests ensure user configuration unchanged after refactoring.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/base/initrd-networking.nix</path>
        <kind>base module</kind>
        <symbol>initrd SSH configuration</symbol>
        <lines>not yet read</lines>
        <reason>Base module for initrd networking (LUKS/ZFS remote unlock). Imported by all hosts. Should be included in namespace export feature tests.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/terranix/base.nix</path>
        <kind>terranix module</kind>
        <symbol>base terraform configuration</symbol>
        <lines>not yet read</lines>
        <reason>Already exported to namespace (flake.modules.terranix.base). Regression tests must validate terraform output equivalence. Provides pattern for namespace exports.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/test-clan/modules/terranix/hetzner.nix</path>
        <kind>terranix module</kind>
        <symbol>hetzner provider configuration</symbol>
        <lines>not yet read</lines>
        <reason>Already exported to namespace (flake.modules.terranix.hetzner). Contains Hetzner VM resource definitions that generate terraform JSON validated by RT-1 test.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/nix-unit/tests/assets/basic.nix</path>
        <kind>test reference</kind>
        <symbol>nix-unit test examples</symbol>
        <lines>1-50</lines>
        <reason>Local nix-unit source provides canonical test pattern examples using expr/expected assertions. Shows proper nix-unit interface: { expr = value; expected = value; } and error testing with expectedError.type. Test strategy document uses pkgs.runCommand wrapper pattern - this shows the underlying nix-unit assertion format that integrates with nix-unit CLI and flake checks.</reason>
      </artifact>
      <artifact>
        <path>~/projects/nix-workspace/nix-unit/README.md</path>
        <kind>documentation</kind>
        <symbol>nix-unit documentation</symbol>
        <lines>1-44</lines>
        <reason>Explains nix-unit advantages: compatible with lib.debug.runTests, allows individual test failures, uses Nix evaluator C++ API for speed. Points to full documentation at https://nix-community.github.io/nix-unit/. Critical context: nix-unit can test eval failures (important for feature tests expected to fail).</reason>
      </artifact>
    </code>
    <dependencies>
      <nix>
        <package name="nixpkgs" version="follows:nixos-unstable" />
        <package name="flake-parts" version="github:hercules-ci/flake-parts" />
        <package name="clan-core" version="git+https://git.clan.lol/clan/clan-core" />
        <package name="import-tree" version="github:vic/import-tree" note="Already in inputs, will be used for feature tests" />
        <package name="terranix" version="github:terranix/terranix" />
        <package name="disko" version="github:nix-community/disko" />
        <package name="srvos" version="github:nix-community/srvos" />
        <package name="nix-unit" version="github:nix-community/nix-unit" note="TO BE ADDED for test framework" />
      </nix>
      <system>
        <tool name="jq" purpose="JSON normalization and comparison in tests" />
        <tool name="diffutils" purpose="Snapshot comparison in regression tests" />
        <tool name="opentofu" purpose="Terraform execution for infrastructure provisioning" />
      </system>
    </dependencies>
  </artifacts>

  <constraints>
1. **CRITICAL - Circular Dependency Avoidance**: perSystem evaluation happens BEFORE flake outputs exist. NEVER access config.flake or inputs.self from within perSystem modules. This creates infinite recursion. Simple tests use nix-unit expr/expected in perSystem (test DATA only). Complex tests use withSystem at flake level (test EXECUTION with flake access). See research document for complete technical analysis.

2. **Test Infrastructure Location**: All test files must be created in ~/projects/nix-workspace/test-clan/ repository, NOT in infra repository. Story context lives in infra for documentation, but implementation happens in test-clan.

3. **Correct Implementation Patterns**:
   - Simple property tests: Define in perSystem.nix-unit.tests using expr/expected (nix-unit pattern)
   - Complex derivation tests: Define at flake level using withSystem (withSystem pattern)
   - Access flake outputs: Use top.config.flake passed to tests at flake level
   - Access perSystem context: Use withSystem to get pkgs from perSystem while at flake level
   - Test organization: tests/nix-unit/ for simple tests, tests/integration/ for complex tests

4. **Test Category Semantics**:
   - Regression: Must pass before AND after refactoring (validates preservation)
   - Invariant: Must always pass (validates clan-core contract)
   - Feature: Expected to FAIL before refactoring, MUST pass after (validates new capabilities)
   - Integration: Must pass before AND after (validates runtime behavior)

5. **Validation Requirements**: Run nix flake show to verify no circular dependencies BEFORE writing tests. Test implementation must not introduce infinite recursion errors. All tests must integrate with nix flake check. Individual tests must be buildable via nix build .#checks.<system>.<test-name>.

6. **Clan-core Integration Requirements**: Invariant tests protect clan-core compatibility requirements that must never break:
   - clan.inventory.machines structure with tags and machineClass
   - clan.inventory.instances with service targeting (roles.controller.machines, roles.peer.tags)
   - specialArgs propagation enabling inputs access in modules
   - Service targeting preservation (hetzner-ccx23 MUST remain zerotier controller)

7. **Test Framework Choice**: Use nix-unit expr/expected for simple property tests (RT-1, IT-1, IT-2, IT-3, FT-1, FT-2). Use withSystem + runCommand/runNixOSTest for complex tests (RT-2, RT-3, VT-1). Both patterns integrate with flake checks but use different evaluation strategies to avoid circular dependencies.

8. **Flake Structure Requirements**: flake.nix must use top@ pattern: top@{ withSystem, config, lib, ... }: to enable access to top.config.flake from flake level. Import nix-unit flake module: inputs.nix-unit.modules.flake.default. Define simple tests in perSystem.nix-unit.tests. Define complex tests in flake.checks using withSystem.

9. **Research Document Authority**: docs/notes/development/research/flake-parts-nix-unit-test-integration.md is the authoritative technical specification for this story. It documents why phase-0-tests failed, explains flake-parts evaluation model, and provides working code examples. When in doubt, refer to this research document.

10. **Prohibited Patterns** (These patterns create circular dependencies and MUST NOT be used):
    - Accessing config.flake from within perSystem
    - Accessing inputs.self outputs from within perSystem
    - Importing test modules in perSystem that expect flake outputs
    - Passing inputs.self to tests in perSystem.checks
    - Any pattern that requires flake outputs to exist during perSystem evaluation
  </constraints>

  <interfaces>
### CORRECT Pattern: Nix-unit expr/expected (Simple Property Tests)

**Use for: RT-1, IT-1, IT-2, IT-3, FT-1, FT-2**

```nix
# tests/nix-unit/regression.nix
{
  "terraform-has-compute-instances" = {
    expr = ''builtins.hasAttr "google_compute_instance" flake.terranix.x86_64-linux'';
    expected = "true";
  };
}

# Integration in perSystem
perSystem = { config, ... }: {
  nix-unit.tests = {
    regression = import ./tests/nix-unit/regression.nix;
    invariant = import ./tests/nix-unit/invariant.nix;
    feature = import ./tests/nix-unit/feature.nix;
  };
};
```

**Why this works**: Test expressions are STRINGS (data) in perSystem, but nix-unit binary evaluates them with complete flake access. No circular dependency because expressions are not evaluated during perSystem evaluation.

### CORRECT Pattern: withSystem at Flake Level (Complex Tests)

**Use for: RT-2, RT-3, VT-1**

```nix
# Flake structure with top@ pattern
top@{ withSystem, config, lib, ... }:
{
  # Normal perSystem (simple tests only)
  perSystem = { config, ... }: {
    nix-unit.tests = { /* simple tests */ };
  };

  # Complex tests at flake level using withSystem
  flake.checks = lib.genAttrs config.systems (system:
    withSystem system ({ pkgs, ... }: {
      machine-builds = import ./tests/integration/machine-builds.nix {
        flake = top.config.flake;  # ✅ CORRECT: Access flake outputs from flake level
        inherit pkgs lib system;    # ✅ CORRECT: Get pkgs from perSystem via withSystem
      };

      vm-boot = pkgs.testers.runNixOSTest {
        name = "test-clan-vm-boot";
        nodes.machine = {
          imports = [ top.config.flake.nixosModules.default ];
        };
        testScript = ''machine.wait_for_unit("multi-user.target")'';
      };
    })
  );
}
```

**Why this works**: Tests defined at flake level, AFTER perSystem evaluation completes. withSystem provides perSystem context (pkgs) while allowing access to complete flake outputs via top.config.flake.

### INCORRECT Patterns (NEVER USE - Creates Circular Dependencies)

```nix
# ❌ WRONG: Accessing config.flake from perSystem
perSystem = { config, ... }: {
  checks.my-test = import ./test.nix {
    flake = config.flake;  # ❌ CIRCULAR: config.flake doesn't exist yet
  };
};

# ❌ WRONG: Accessing inputs.self outputs from perSystem
perSystem = { ... }: {
  checks.my-test = import ./test.nix {
    self = inputs.self;  # ❌ CIRCULAR: inputs.self outputs don't exist yet
  };
};

# ❌ WRONG: Importing test modules expecting flake outputs in perSystem
perSystem = { pkgs, ... }: {
  checks = {
    test = (import ./test.nix { inherit self; }).test;  # ❌ CIRCULAR
  };
};
```

### Test File Examples

**Simple Test (tests/nix-unit/invariant.nix):**
```nix
{
  "clan-inventory-valid" = {
    expr = ''
      let inv = flake.clan.inventory;
      in builtins.hasAttr "machines" inv && builtins.hasAttr "instances" inv
    '';
    expected = "true";
  };

  "zerotier-controller-targeting" = {
    expr = ''
      let zerotier = flake.clan.inventory.instances.zerotier;
      in builtins.hasAttr "controller" zerotier.roles
    '';
    expected = "true";
  };
}
```

**Complex Test (tests/integration/machine-builds.nix):**
```nix
{ flake, pkgs, lib, system }:

pkgs.runCommand "machine-builds-test" {
  machines = builtins.attrNames flake.nixosConfigurations;
} ''
  echo "Validating ${builtins.toString (builtins.length machines)} machine configs..."

  ${lib.concatMapStringsSep "\n" (m: ''
    config="${flake.nixosConfigurations.${m}.config.system.build.toplevel}"
    if [ -d "$config" ]; then
      echo "✅ ${m} builds successfully"
    else
      echo "❌ ${m} failed to build"
      exit 1
    fi
  '') machines}

  echo "pass" > $out
''
```

### Validation Commands

```bash
# Verify no circular dependencies
nix flake show

# Test individual checks
nix build .#checks.x86_64-linux.nix-unit
nix build .#checks.x86_64-linux.machine-builds
nix build .#checks.x86_64-linux.vm-boot

# Run complete test suite
nix flake check
```

### Clan Inventory Structure Interface
```nix
# Expected clan.inventory structure preserved by invariant tests
clan.inventory.machines = {
  machine-name = {
    tags = [ "nixos" "cloud" "provider" ];
    machineClass = "nixos";
  };
};

clan.inventory.instances = {
  service-name = {
    module = { name = "service"; input = "clan-core"; };
    roles.role-name.machines."machine-name" = { };  # Specific machine targeting
    roles.role-name.tags."tag-name" = { };  # Tag-based targeting
  };
};
```

### SpecialArgs Interface
```nix
# Pattern validated by IT-3
clan.specialArgs = { inherit inputs; };

# Enables in host modules:
{ inputs, lib, ... }: {
  imports = [
    inputs.srvos.nixosModules.server  # External input access
  ];
}
```
  </interfaces>

  <tests>
    <standards>
Tests use HYBRID approach combining nix-unit expr/expected for simple property tests and withSystem at flake level for complex derivation tests. CRITICAL: All test patterns avoid circular dependencies by following flake-parts evaluation model (perSystem runs BEFORE flake outputs exist). Simple tests define test DATA as strings in perSystem.nix-unit.tests (nix-unit pattern). Complex tests define test EXECUTION at flake level using withSystem for perSystem context + top.config.flake for flake outputs (withSystem pattern). All tests integrate with nix flake check. Validation requirement: nix flake show must complete without infinite recursion errors. Test categories follow test-driven refactoring methodology: regression/invariant tests establish baseline (what must not break), feature tests define target (what must be achieved), integration tests validate runtime (what must work in practice). Reference docs/notes/development/research/flake-parts-nix-unit-test-integration.md for complete technical specification.
    </standards>
    <locations>
Test directory structure in test-clan repository (REVISED from phase-0-tests failure analysis):
- tests/nix-unit/ - Simple property tests using expr/expected pattern (RT-1, IT-1, IT-2, IT-3, FT-1, FT-2)
  - tests/nix-unit/regression.nix - Terraform output structure validation
  - tests/nix-unit/invariant.nix - Clan inventory, service targeting, specialArgs tests
  - tests/nix-unit/feature.nix - Dendritic feature tests (expected to fail)
- tests/integration/ - Complex derivation tests using withSystem pattern (RT-2, RT-3, VT-1)
  - tests/integration/machine-builds.nix - NixOS closure and build validation
  - tests/integration/vm-boot.nix - VM boot tests with runNixOSTest
- Integration points:
  - perSystem.nix-unit.tests imports tests/nix-unit/*.nix files
  - flake.checks uses withSystem to import tests/integration/*.nix files
  - All tests accessible via nix flake check and individual nix build commands
    </locations>
    <ideas>
### Regression Test Ideas

**RT-1 Enhancement**: Add terraform resource count validation - ensure number of VMs, networks, firewalls unchanged. Catch accidental resource additions/removals.

**RT-2 Enhancement**: Add closure size tracking - detect if refactoring accidentally increases system closure size (indicates dependency bloat).

**RT-3 Enhancement**: Test build reproducibility - build same config twice, compare store paths to detect non-determinism.

**RT-4 New**: Configuration evaluation time - track how long nixosConfiguration evaluation takes, detect if refactoring slows evaluation significantly.

### Invariant Test Ideas

**IT-1 Enhancement**: Validate clan vars generation works - ensure clan secrets can still be generated for all service instances after refactoring.

**IT-2 Enhancement**: Test service targeting resolution - verify clan-core correctly resolves which machines receive which service configurations.

**IT-3 Enhancement**: Validate module evaluation doesn't have circular dependencies - detect infinite recursion scenarios early.

**IT-4 New**: Disko configuration preservation - ensure disk layouts unchanged (critical for deployed VMs, modifications could cause data loss).

### Feature Test Ideas

**FT-1 Enhancement**: Count discovered modules - verify import-tree finds expected number of modules (prevents silent module exclusion).

**FT-2 Enhancement**: Test external flake consumption - verify another flake can import test-clan's namespace exports.

**FT-3 Enhancement**: Check import path types - detect any remaining relative imports after refactoring claims self-composition complete.

**FT-4 New**: Automatic host collection - if implementing auto nixosConfigurations generation, test all expected machines appear.

### Integration Test Ideas

**VT-1 Enhancement**: Test zerotier network connectivity - verify VMs can actually communicate over zerotier after deployment.

**VT-2 New**: Clan service functionality - test emergency-access SSH keys work, users-root creates expected users, tor service functional.

**VT-3 New**: Deployment idempotency - deploy configuration twice, verify second deployment is no-op (no unexpected changes).

**VT-4 New**: Rollback capability - test that previous system generations remain bootable after refactoring.

### Cross-cutting Test Ideas

**Snapshot diffing tool**: Create script to generate human-readable diffs between baseline and current snapshots for investigation.

**Test result dashboard**: Generate markdown summary of test results by category with pass/fail counts and failed test details.

**Continuous baseline updates**: After validated refactoring, capture new baselines for next iteration (baselines evolve with intentional changes).

**Property-based testing**: Use hypothesis-style testing for configuration properties (e.g., all machines have SSH, all services have targeting).
    </ideas>
  </tests>
</story-context>
